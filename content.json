{"meta":{"title":"Moonm3n's blog","subtitle":"","description":"","author":"Yueyang Zhan","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"TiDB-PD","slug":"TiKV-PD","date":"2022-03-22T06:45:27.000Z","updated":"2022-03-28T10:58:04.575Z","comments":true,"path":"2022/03/22/TiKV-PD/","link":"","permalink":"http://example.com/2022/03/22/TiKV-PD/","excerpt":"PD 是 TiDB 里的全局中心总控节点, 主要负责全局元信息的存储以及 TiKV 集群负载均衡调度.","text":"PD 是 TiDB 里的全局中心总控节点, 主要负责全局元信息的存储以及 TiKV 集群负载均衡调度. 实现原理PD 是一个逻辑上的单点, 物理上是一个集群, 集成 etcd, 支持故障恢复, 保证了强一致性.PD 功能可以分为三类: 路由 元数据管理 调度 TiKV 中的 Region Leader 与 Store 会定期向 PD 发送 Heartbeat, Heartbeat 中包含了 Region 和 Store 的各种状态信息,PD 根据状态信息来调度 TiKV 集群的负载均衡, 将 Operator 通过 Heartbeat response 回复给 TiKV. 基本概念1. SchedulerScheduler 是用来调度资源的接口, 调度器通过状态信息生成 Operator. 2. OperatorOperator 是 PD 对 TiKV 的调度操作的集合, 可以由其他 Operator 组合而成. Selector/FilterSelector 与 Filter 负责选择调度操作的 source 与 target. ControllerController 负责控制整个调度的速度. CoordinatorCoordinator 在 Region Heartbeat 会检测 Region 是否需要调度, 如果需要, 则进行调度. PD 中有许多调度器, 每个调度器是独立运行的, 有着不同的调度目的.常见的调度器有: balance-leader-scheduler: 保持不同节点的 Leader 均衡. balance-region-scheduler: 保持不同节点的 Region 均衡. hot-region-scheduler: 保持不同节点的读写热点 Region 均衡. evict-leader-{store-id}: 驱逐某个节点的所有 Leader. 调度流程调度的流程大体上可以分为三部分: 信息收集Region Leader 周期性地上报 RegionHeartbeat 心跳, 包含了 Region 范围, 副本分布, 副本状态, 数据量, 读写流量等数据.Store 周期性地上报 StoreHeartbeat 心跳, 包含了 Store 的基本信息, 容量, 剩余空间, 读写流量等数据. 生成调度 执行调度将 Operator Step 下发给对应 Region 的 Leader. 集群的元信息、TSO 信息、Region 信息 持久化在 etcd 中.Store 与 Region 的状态存在 cache 中.","categories":[{"name":"databases","slug":"databases","permalink":"http://example.com/categories/databases/"}],"tags":[{"name":"TiDB","slug":"TiDB","permalink":"http://example.com/tags/TiDB/"}]},{"title":"tinykv-project3-MultiRaftKV-PartB","slug":"tinykv-project3-MultiRaftKV-PartB","date":"2022-03-05T12:52:50.000Z","updated":"2022-04-10T06:30:01.057Z","comments":true,"path":"2022/03/05/tinykv-project3-MultiRaftKV-PartB/","link":"","permalink":"http://example.com/2022/03/05/tinykv-project3-MultiRaftKV-PartB/","excerpt":"","text":"summary3B 主要涉及到 领导人变更(transfer leader) 节点变更(conf change) 以及 region 分裂(region split). transfer leadertransfer leader 请求不需要作为一个 entry 在 Raft group 之中同步,peer 在收到该请求时, 只需要向下传递给 Raft 层执行, 完成后返回 response 即可. conf changeconf change 请求的主要作用是向 Raft group 中添加或删除 peer, 分为 add node 和 remove node 两种类型. add node: 在 Raft group 中添加节点, peer 只需要更改自己 peerStore 和 ctx.storeMeta 中的 region,向其中添加 peer 即可. store_worker 在向该 peer 发送消息时才会新建 peer. 吐槽: conf change 的消息类型以及处理方法为啥这么特别而又别扭? 是有什么特殊的考虑吗. remove node: 在 Raft group 中删除节点, 如果被删除的不是自己, peer 的行为与 add node 时类似,如果删除的是自己, 直接调用 destroyPeer() 函数即可. region split在数据写入后, split checker 会定期检测 region 的大小, 符合条件时, 生产 region split 的 key. 问题记录1. handle raft message failed storeID 2, region 1 not exists but not tombstoneprocess remove node 删除自己时, 首先调用了 destroyPeer() 修改 RaftLocalState tombstone,后续没有判断这一情况, WriteRegionState 时又将 RaftLocalState 改为了 normal. 2. panic: [region 1] 6 unexpected raft log index: lastIndex 0 &lt; appliedIndex 5164add node 在 store_worker 实际创建 peer 时报错.raftState 和 applyState 分别从 kv engine 和 raft engine 中根据 region id 读取出,applyState 是正常的, raftState 却是空的. 原因: process 多个 entry 时, conf change 调用 destroyPeer 清空了 store,下一条 entry 执行时又会更新 apply index, 重新写入了 applyState. process entry 时应该判断 d.stopped, 如果已经停止, 直接 return. 3. panic: request timeoutRaft group 中只有两个节点时, 再删除一个节点, 如果这个节点正好是 leader,可能在 commit 消息发送前便把自己 destroy 了, 另一个节点便无法得知这一情况的发生, 永远无法选举成功. 应该先 transfer leader 给剩下的节点, 直接返回错误, client 会进行重试, 再由剩下的节点来处理 remove node. 4. panic: resp.Responses[0].CmdType != raft_cmdpb.CmdType_Put在三个节点的集群中删除一个节点后会发生这个问题. 在 append proposal 处打日志后发现,同一个 index 的 proposal append 了多次. 12342022/03/17 15:32:08.334664 peer_msg_handler.go:598: \u001b[0;37m[info] [region 1] 3 append proposal type Snap, index 16681\u001b[0m2022/03/17 15:32:08.334670 peer_msg_handler.go:598: \u001b[0;37m[info] [region 1] 3 append proposal type Snap, index 16681\u001b[0m2022/03/17 15:32:08.334682 peer_msg_handler.go:598: \u001b[0;37m[info] [region 1] 3 append proposal type Put, index 16681\u001b[0m2022/03/17 15:32:08.334686 peer_msg_handler.go:598: \u001b[0;37m[info] [region 1] 3 append proposal type Put, index 16681\u001b[0m propose entry 后, Raft 的 last index 没有发生变化. transferLeader 产生的错误没有正确返回. 5. test_test.go:221: \u001b[0;31m[fatal] get wrong value, client 17与问题 4 相同. 6. panic: [region 1] 4 meta corruption detected测试用例: TestSplitConfChangeSnapshotUnreliableRecoverConcurrentPartition3B 出错代码行: /root/tinykv/kv/raftstore/peer_msg_handler.go:867 +0x417 destroyPeer() 中删除 storeMeta regionRanges 中的 regionItem 时,发现并没有对应的 regionItem. applySnapshot() 后不应该在 storeMeta 中删除 prevRegion 的 regionRanges,在分区的情况下, 一个节点并没有收到 split message,分区恢复后, 新分裂的 region 的 peer 先被创建并收到 snapshot, 向 storeMeta 中写入,另一个 peer 收到 snapshot 时如果删除 prevRegion, 就会导致 panic.prevRegin 的 endKey 恰好是另一个 peer 的已经写入的 endKey, 因此不能删除它. 7. panic: split peer count not equal to region peer count自定义的 panic, split request 中的 id 的数目可能与 目前集群中的节点数不相同, 应该拒绝这个请求. 8. panic: entries’ high 586 is out of bound, lastIndex 584leader 向 follower 连续发送两次快照, follower 应用第一个快照并返回 response 后,leader 会向 follower 发送 append entries, 此时 follower 应用了第二个快照,follower 接受到 entries 后发现他们的 index 比自己的 last index 小, 尝试替换自己的日志,但自己又没有这些日志, 便会引发这个错误. 解决方法: 不调用 panic 直接返回即可. 9. request timeout3B 中会遇到各种各样的 request timeout. 9.1 send message err: message is dropped在没有分区的情况下, leader 一个时间段内发送的所有消息都丢失了. 没有查明原因, 这个问题会导致 leader 发送的 snapshot 很容易丢失,又因为在 2C 中优化了快照的发送次数, 很容易导致超时. 9.2. tombstone peer receives a stale message超时前出现不停出现 tombstone peer receives a stale message 的日志. 9.3 1_12_14677 is registered more than 1 timesend snapshot 后出现这条错误. 超时前不停地出现这条错误.当集群中只有两个节点 1, 2 时, 1 向 2 发送快照, 2 handel 后发送的 response 丢失了,这时 1 无法 commit 新的 entry, 也无法发送同样的快照给2, 集群就这样永远不可用了. l.Index2Position(i) &lt; len(l.entries)","categories":[{"name":"database project","slug":"database-project","permalink":"http://example.com/categories/database-project/"}],"tags":[{"name":"tinykv","slug":"tinykv","permalink":"http://example.com/tags/tinykv/"}]},{"title":"tinykv-project2-RaftKV-PartC","slug":"tinykv-project2-RaftKV-PartC","date":"2022-02-24T01:48:10.000Z","updated":"2022-03-03T08:49:09.658Z","comments":true,"path":"2022/02/24/tinykv-project2-RaftKV-PartC/","link":"","permalink":"http://example.com/2022/02/24/tinykv-project2-RaftKV-PartC/","excerpt":"tinykv project 2 part b, 实现快照机制, 定期对日志进行压缩.","text":"tinykv project 2 part b, 实现快照机制, 定期对日志进行压缩. snapshot 的实现分为两个部分. 实现日志的定期清理. 实现 snapshot 数据的发送. 问题记录1. panic: requested entry at index is unavailable这个错误发生在节点重启, 从 storage 中恢复 entries 时. debug 发现 storage 中仅存储了 lo 所在的那一个 entry, 没有 lo 到 hi 之间的 entries.回归测试 2b 后发现也出现了这个问题, 应该是写 2c 时影响到了. 修改 SaveRaftReady() 中应用 snapshot 和 append entries 的顺序后修复. 2. FAIL: TestSnapshotUnreliableRecoverConcurrentPartition2C没有任何错误提示.看日志发现 leader 在不停地 send append.debug 发现 first index 小于 truncated index 了, 怀疑 truncated index 或者 first index 的持久化有问题.debug 发现 send snapshot 的逻辑有问题, 无法发送 snapshot. 3. FAIL: panic: runtime error: slice bounds out of range [1186:384]更改 raft log 的 first index 时没有修改 entries 数组, 导致 从 entries 数组中取 entry 的逻辑出错. 4. panic: Key not foundleader 请求生成 snapshot 后分区恢复, 出现了新 leader, 新 leader 再次请求 snapshot 时便会触发这个问题.apply snapshot 时 WriteRegionState 后解决. 5. panic: request timeoutleader 一直在请求 snapshot, 随后就 timeout 了.apply snapshot 时 WriteRegionState 后解决.","categories":[{"name":"database project","slug":"database-project","permalink":"http://example.com/categories/database-project/"}],"tags":[{"name":"tinykv","slug":"tinykv","permalink":"http://example.com/tags/tinykv/"}]},{"title":"tinykv-project2-RaftKV-PartB","slug":"tinykv-project2-RaftKV-PartB","date":"2022-02-03T09:56:59.000Z","updated":"2022-04-06T14:02:46.678Z","comments":true,"path":"2022/02/03/tinykv-project2-RaftKV-PartB/","link":"","permalink":"http://example.com/2022/02/03/tinykv-project2-RaftKV-PartB/","excerpt":"tinykv project 2 part b, 利用 Raft 模块构建容错的 KV 存储服务.","text":"tinykv project 2 part b, 利用 Raft 模块构建容错的 KV 存储服务. Basic在 Project2 Part A 中我们实现了 Raft 算法的 Leader election 和 Log replication 部分. 也实现了 Ready 相关的几个函数, 能够抽取 Raft 层的变更信息. 整个 2A 的主要工作都是在 Raft 层. 在 Project2 Part B 中, 我们把 KV 存储引擎用作 Raft 中的状态机, 将 Client 的请求作为日志, 扩展出一个容错的 KV 存储服务. 首先需要了解几个基本的概念: Store: 一个 tinykv-server. Peer: tinykv-server 中运行的一个 Raft node, 一个 Store 上可能运行有多个 Peer, 每个 Peer 所属于不同的 Region, 在 2B 中, 只会涉及到一个 Region. Region: Raft group. Implement peer storage在这一步中, 我们需要将 Raft 层的状态持久化. Raft 论文中提到的需要持久化的状态有: currentTerm: 节点当前的任期, 既 HardState 中的 Term. votedFor: 节点给谁投了票, 既 HardState 中的 Vote. 如果不持久化 Vote, 节点投票后重启会产生一个节点在一个 Term 中投出两张票的现象. log[]: 节点当前的日志. 与 Raft 论文不同, tinykv 中还需要将 Commit 和 Region 信息持久化. tinykv 中的绝大多数 request 都是幂等的. 具体到代码中, 我们需要实现 SaveReadyState() 与 Append() 两个函数, 2B 中并不涉及快照, ApplySnapshot() 函数暂时不需要实现. Implement Raft ready processHandleRaftReady get the ready from Raft module. persisting log entries. applying committed entries. sending Raft message to other peers. 问题记录1. panic: find no region for 30203030303030303030raft.go newRaft()优先使用 storage 中的 confState.Nodes 的值. 2. panic: runtime error: index out of range [18446744073709551611] with length 1raft.go sendAppend()index 处理有问题 3. 空指针snap 的 response 需要携带 Region, cd 的 Txn 需要赋值, 否则会出现空指针异常. 4. can’t call command header on leader nWaitRespWithTimeout 超时了.router.peerSender 管道满了不停地向 router.peerSender 中发送消息, 导致管道堵塞, 引发卡死.Ready() 函数里没有清空 msg. 5. panic: [region 1] 2 unexpected raft log index— FAIL: TestPersistPartition2B (27.40s)panic: [region 1] 2 unexpected raft log index: lastIndex 33539 &lt; appliedIndex 33810 [recovered] 看起来像是 lastIndex 持久化的逻辑有问题, 重启节点时监测到 lastIndex 比 appliedIndex 更小, 引发 panic.修改了持久化的逻辑后变成了偶现 bug, 1% 几率出现. 修复问题 6 后消失. 6. panic: runtime error: index out of range [1091] with length 1087偶现 bug, 3% 几率出现.bug 出现时, 这两个 index 的差值绝大多数时候为 5, length 为 1087 时, 最后一个元素应该是 [1086].看了日志, 在 partition 情况下才会发生. leader progress 里存储的 next 比自身的 lastIndex 大了更多.加日志后实锤, append entries 返回了大于 leader.lastIndex 的 index, leader 用这个 index 更新了 next,于是出现了数组越界. 错误原因:becomeFollower 时将 Vote 设置为了 None, partition 后有可能选出两个 Leader. 7. panic: len(resp.Responses) != 1偶现 bug, 1% 几率出现.panic: len(resp.Responses) != 1 goroutine 439 [running]:github.com/pingcap-incubator/tinykv/kv/test_raftstore.(*Cluster).MustPutCF(0xc00011f5c0, 0x47f01a0, 0x7, 0xc22a37f5d0, 0xa, 0x10, 0xc22a37f5e0, 0x9, 0x10) /Users/moon/GolandProjects/tinykv/kv/test_raftstore/cluster.go:308 +0x24dgithub.com/pingcap-incubator/tinykv/kv/test_raftstore.(*Cluster).MustPut(…) /Users/moon/GolandProjects/tinykv/kv/test_raftstore/cluster.go:298github.com/pingcap-incubator/tinykv/kv/test_raftstore.GenericTest.func1(0x1, 0xc000001e00) /Users/moon/GolandProjects/tinykv/kv/test_raftstore/test_test.go:211 +0x41fgithub.com/pingcap-incubator/tinykv/kv/test_raftstore.runClient(0xc000001e00, 0x1, 0xc21c12fb60, 0xc21e28acf0) /Users/moon/GolandProjects/tinykv/kv/test_raftstore/test_test.go:27 +0x7acreated by github.com/pingcap-incubator/tinykv/kv/test_raftstore.SpawnClientsAndWait /Users/moon/GolandProjects/tinykv/kv/test_raftstore/test_test.go:37 +0xb2FAIL github.com/pingcap-incubator/tinykv/kv/test_raftstore 23.630sFAILrm -rf /tmp/test-raftstore 修复问题 6 后消失.","categories":[{"name":"database project","slug":"database-project","permalink":"http://example.com/categories/database-project/"}],"tags":[{"name":"tinykv","slug":"tinykv","permalink":"http://example.com/tags/tinykv/"}]},{"title":"tinykv-project2-RaftKV-PartA","slug":"tinykv-project2-RaftKV-PartA","date":"2022-01-17T07:30:04.000Z","updated":"2022-02-10T07:57:54.760Z","comments":true,"path":"2022/01/17/tinykv-project2-RaftKV-PartA/","link":"","permalink":"http://example.com/2022/01/17/tinykv-project2-RaftKV-PartA/","excerpt":"tinykv project 2 part a, 实现基本的 Raft 算法.","text":"tinykv project 2 part a, 实现基本的 Raft 算法. 2aa leader electionleader election 流程 什么时候开始选举? follow 在超时时间内没有收到心跳, 认为 leader 已经失效, 转变为 candidate 开始选举. 选举超时时, 没有节点赢得选举, 所有 candidate 会随机等待一段时间, 然后重新选举. candidate 是怎样选举的? 成为 candidate 后首先自增 term. 为自己投票. 重制选举超时计时器. 发送请求投票的 RPC 给其他所有服务器. candidate 怎样结束选举? 接收到大多数节点的选票, 成为 leader 并立即向其他节点发送心跳. 发现了其他 leader, 且这个 leader 的 term 不小于自己的 term. 选举超时, candidate 会随机等待一段时间, 再次自增 term, 然后重新选举. follower 怎样投票? 每个 follower 只会对一个 term 投一次票. 申请选票的 candidate 必须包含所有已提交的日志. leader election 实现Raft 算法的 leader election 是在时钟超时时触发的, tinykv 的 Raft 算法采用逻辑时钟来进行计时, 首先需要确定在哪里处理超时, 开始 leader election.观察一下 Raft 结构体的成员, 逻辑时钟的值应该存放在 heartbeatElapsed 和 electionElapsed 这两个变量中. heartbeatElapsed 记录了上次心跳超时以来的 ticks 数, 只有 leader 会保持这个值, 超时时发送心跳. electionElapsed 对 leader 和 candidate 而言, 记录了上次选举超时以来的 ticks 数; 对 follower 而言, 记录了上次收到 leader 的有效消息以来的 ticks 数. 超时时启动选举. 比较合理的做法是在 tick() 方法中递增逻辑时钟并监测超时. tick() 方法中,如果当前节点是 leader, 则更新 heartbeatElapsed 和 electionElapsed 的值, 并且检查是否超时.如果超时, 则转换为 candidate 节点. 如果当前节点是 candidate, 则检查是否超时, 如果超时, 则重新选举. 如果当前节点是 follower, 则检查是否收到 leader 的有效消息, 如果收到, 则更新 electionElapsed 的值.如果没有收到 leader 的有效消息, 则重新选举. 如果当前节点是 candidate, 则检查是否收到 leader 的有效消息, 如果收到, 则转换为 follower 节点. newRaft() 需要处理的消息类型: MessageType_MsgHup 成为 candidate 并开始选举. MessageType_MsgBeat 只有 leader 会接受这个消息, 向所有 peer 广播心跳. MessageType_MsgRequestVote MessageType_MsgRequestVoteResponse 只有 candidate 会接受这个消息. 2ab log replicationlog replication 相关概念日志的几个 index: stabled: 已经被持久化的日志的最大 index. committed: 已经被提交的日志的最大 index. applied: 已经被应用的日志的最大 index. 日志先被 stabled, 再被 commit, 最后被 applied. snapshot/first…..applied….committed….stabled…..last log replication 流程 节点成为 leader 时将所有 peer 的 nextIndex 初始化为 lastIndex + 1, 所有 peer 的 matchIndex 初始化为 0. 接收到 client 请求, 将请求添加到自己的日志中. 发送 AppendEntries RPC 给所有 peer, 并等待所有 peer 的回复. log replication 实现日志的 index 从 1 开始, committed, applied, stabled 应该日志的 index 而不是切片的下标. 2ac raw node interfaceReady{}Ready 封装了可以读取、持久化、提交的状态. Entries: specifies entries to be saved to stable storage BEFORE messages are sent.CommittedEntries: specifies entries to be committed to a store/state-machine.These have previously been committed to stable store.Ready() Advanced()","categories":[{"name":"database project","slug":"database-project","permalink":"http://example.com/categories/database-project/"}],"tags":[{"name":"tinykv","slug":"tinykv","permalink":"http://example.com/tags/tinykv/"}]},{"title":"Raft-论文研读","slug":"Raft-论文研读","date":"2022-01-17T05:59:05.000Z","updated":"2022-01-17T16:00:51.764Z","comments":true,"path":"2022/01/17/Raft-论文研读/","link":"","permalink":"http://example.com/2022/01/17/Raft-%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/","excerpt":"","text":"","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"Raft","slug":"Raft","permalink":"http://example.com/tags/Raft/"}]},{"title":"tinykv-project1-StandaloneKV","slug":"tinykv-project1-StandaloneKV","date":"2022-01-16T11:37:20.000Z","updated":"2022-04-15T13:16:37.759Z","comments":true,"path":"2022/01/16/tinykv-project1-StandaloneKV/","link":"","permalink":"http://example.com/2022/01/16/tinykv-project1-StandaloneKV/","excerpt":"tinykv project 1, 基于 badger 构造一个单机的支持列族存储的 gRPC 服务.","text":"tinykv project 1, 基于 badger 构造一个单机的支持列族存储的 gRPC 服务. 目标基于 badger 构造一个单机的支持列族存储的 gRPC 服务.这一服务提供四种基本操作: Put/Delete/Get/Scan. Put: 向指定列族中写入. Get: 从指定列族中读取. Delete: 删除指定列族的指定值. Scan: 从指定列族中顺序读取多个值. Implement standalone storage engine题目解析在这一步中我们要实现 Storage 接口的一个实现类 StandAloneStorage, 在 TinyKV 中, Storage 接口有三个实现类: MemStorage, RaftStorage 和 StandAloneStorage. StorageStorage 可以理解为存储层的抽象, 提供 Start(), Stop(), Write(), Reader() 四种方法. Start() 与 Stop() 方法只有 RaftStorage 类会用到, 用于启动/停止底层 Raft 节点, 题目中也没有要求我们实现这两个方法. ( 感觉 Start() 与 Stop() 方法中的两行 // Your Code Here (1). 应该删掉 ) Write() 方法向存储层中写入变更, 变更的类型可以是 Put 或 Delete. Reader() 方法返回一个 StorageReader 类, 提供 GetCF(), IterCF(), Close() 三种方法.总的来说, Storage 提供 Write(), GetCF() 和 IterCF() 三种操作数据的方法. MemStorageMemStorage 是 Storage 的纯内存实现, 硬编码了三个列族: CfDefault, CfLock 和 CfWrite. 每个列族是一颗红黑树,Write(), GetCF(), IterCF() 直接调用了红黑树的 ReplaceOrInsert(item)、Delete(item)、Get(item) 方法. Project 4 测试时使用的 Storage 便是 MemStorage. RaftStorageRaftStorage 是 Storage 的分布式实现. 当我们 Run TinyKV with TinySQL 时, 默认会使用这个 Storage. StandAloneStorageStandAloneStorage 是 Storage 的单机实现, 我们要实现的便是这它. 实现思路看了题目之后一脸懵逼, 还好 Storage 接口还有其他两个实现类 MemStorage 与 RaftStorage. 读了读它们的代码, 题目中要求基于 badger key/value API, 而 MemStorage 使用的是红黑树, 只能参考一下 Write() 时处理 Modify 的方法, 其他部分没有参考价值.还剩下 RaftStorage , RaftStorage Start() 时根据 config 新建了一些 client 和 worker 并启动, Stop() 时将它们停止.Write() 时, RaftStorage 将 Modify 转换为 Put 或 Delete, 然后将它们打包成 request 发送到 Raft 层. 这里并没有写入 badger 相关的代码.GetCF() 时, RaftStorage 直接调用 engine_util 中的方法在 badger 中读取, IterCF() 也类似.看了看 engine_util 中的方法, 原来题目中提到的 badger 的操作都在这, 接下来怎么写就比较清晰了. StandAloneStorage 的 Write() 方法只要将 Modify 解析为 Put 或 Delete, 再调用 engine_util 中的方法写入或删除就可以了.Reader() 方法只要新建一个事务, 再新建一个类似 RegionReader 的 Reader 即可.Reader Close() 时记得调用 Discard() 方法结束事务. Implement service handlers题目解析在上一步我们实现了 StandAloneStorage, 但它的接口和题目中咱们的最终目标 Put/Delete/Get/Scan 还不太一样,在这一步中我们要利用 StandAloneStorage 实现 RawPut/RawDelete/RawGet/RawScan 这四个方法, 处理 request, 返回对应的 response. 实现思路要实现的四个方法属于 Server 这个类, Server 类中正好有 Storage 这一属性, 这算是衔接上了.Region 是 Multi-Raft 中的一个概念, 在这一步中我们还没有涉及到 Raft, 不知道为什么类似 RawGetResponse 这样的类中会有 RegionError 这样的属性, 还是先忽略吧. RawGet从 Storage 中获取 Reader, 再调用 Reader 的 GetCF 即可. 注意出错时要将错误信息赋值给 response.Error, 没找到结果时要将 response.NotFound 设置为 True. RawPut &amp; RawDelete先构建 Modify, 再调用 Storage 的 Write 方法即可. RawScan从 Storage 中获取 Reader, 再从 Reader 中获取 Iter, Seek 到对应的 Key 读取最多 Limit 个值即可. 其他在 macOS 上切换 go 版本用 1.17.5 版本的 go 运行 project 时会有奇怪的 errorfatal error: unexpected signal during runtime execution.看了一下 issues 应该是 go 版本的锅, 降级到 1.16.x 便可. 在 macOS 中使用 brew 可以方便地管理软件的版本. 1234567# 安装 gobrew install go# 安装 go 1.16brew install go@1.16# 切换到 go 1.16brew unlink gobrew link go@1.16","categories":[{"name":"database project","slug":"database-project","permalink":"http://example.com/categories/database-project/"}],"tags":[{"name":"tinykv","slug":"tinykv","permalink":"http://example.com/tags/tinykv/"}]},{"title":"oceanbase-competition-final","slug":"oceanbase-competition-final","date":"2021-12-25T14:07:57.000Z","updated":"2022-01-06T13:18:59.119Z","comments":true,"path":"2021/12/25/oceanbase-competition-final/","link":"","permalink":"http://example.com/2021/12/25/oceanbase-competition-final/","excerpt":"","text":"doing","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[]},{"title":"15-445 BUFFER POOL","slug":"CMU-15-445-PROJECT-1-BUFFER-POOL","date":"2021-12-14T13:49:17.000Z","updated":"2021-12-14T14:10:22.955Z","comments":true,"path":"2021/12/14/CMU-15-445-PROJECT-1-BUFFER-POOL/","link":"","permalink":"http://example.com/2021/12/14/CMU-15-445-PROJECT-1-BUFFER-POOL/","excerpt":"","text":"","categories":[{"name":"database course","slug":"database-course","permalink":"http://example.com/categories/database-course/"}],"tags":[{"name":"cmu 15-445","slug":"cmu-15-445","permalink":"http://example.com/tags/cmu-15-445/"}]},{"title":"oceanBase 数据库大赛","slug":"oceanBase-数据库大赛","date":"2021-11-25T06:49:26.000Z","updated":"2022-01-06T07:15:16.780Z","comments":true,"path":"2021/11/25/oceanBase-数据库大赛/","link":"","permalink":"http://example.com/2021/11/25/oceanBase-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%A7%E8%B5%9B/","excerpt":"","text":"赛题描述在开源版本 OceanBase 的基础上, 针对 Nested Loop Join 场景做性能优化. 采用 sysbench 基准测试中 Throughput 的 events/s (eps) 这一项作为排名依据. 赛题解析什么是 Nested Loop Join?Nested Loop Join 是一种常见的数据库查询操作, 其中两个表的数据量相对较小, 且两个表的关联关系相对较简单.Nested Loop Join 的基本原理是每次从左表获取一行, 然后用这行数据和右表进行 Join. 与右表进行 Join 时, 可以通过索引查询降低复杂度. 表结构123456789101112131415local queryquery = string.format([[ CREATE TABLE t%d( c1 int primary key, c2 int, c3 int, v1 CHAR(60), v2 CHAR(60), v3 CHAR(60), v4 CHAR(60), v5 CHAR(60), v6 CHAR(60), v7 CHAR(60), v8 CHAR(60), v9 CHAR(60) )]], table_id)do_query(drv, con, &quot;create index t2_i1 on t2(c2) local&quot;)do_query(drv, con, &quot;create index t2_i2 on t2(c3) local&quot;)ival = sysbench.rand.default(1, sysbench.opt.table_size)left_min = ival - 100;left_max = ival + 100;cond = string.format(&quot;A.c1 &gt;= %d and A.c1 &lt; %d and A.c2 = B.c2 and A.c3 = B.c3&quot;, left_min, left_max)query = &quot;select /*+ordered use_nl(A,B)*/ * from t1 A, t2 B where &quot; .. cond 查询语句123456789101112131415161. 原始查询语句 select /*+ordered use_nl(A,B)*/ * from t1 A, t2 B where A.c1 &gt;= 100 and A.c1 &lt; 200 and A.c2 = B.c2 and A.c3 = B.c3; select /*+ordered use_nl(A,B)*/ * from t1 A, t2 B where A.c1 &gt;= 100 and A.c1 &lt; 200 and A.c2 = B.c2 and A.c3 = B.c3; explain select /*+ordered use_nl(A,B)*/ * from t1 A, t2 B where A.c1 &gt;= 100 and A.c1 &lt; 200 and A.c2 = B.c2 and A.c3 = B.c3;2. 当 A.c1 = A.c2 时, 改写后的查询语句 select /*+ordered use_nl(A,B)*/ * from t1 A, t2 B where A.c1 &gt;= 100 and A.c1 &lt; 200 and B.c2 &gt;= 100 and B.c2 &lt; 200 and A.c3 = B.c3; select /*+ordered use_nl(A,B)*/ * from t1 A, t2 B where A.c1 &gt;= 100 and A.c1 &lt; 200 and B.c2 &gt;= 100 and B.c2 &lt; 200 and A.c3 = B.c3; explain select /*+ordered use_nl(A,B)*/ * from t1 A, t2 B where A.c1 &gt;= 100 and A.c1 &lt; 200 and B.c2 &gt;= 100 and B.c2 &lt; 200 and A.c3 = B.c3;","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[]},{"title":"GFS 论文研读","slug":"GFS-论文研读","date":"2021-11-13T05:27:52.000Z","updated":"2022-01-17T15:59:25.181Z","comments":true,"path":"2021/11/13/GFS-论文研读/","link":"","permalink":"http://example.com/2021/11/13/GFS-%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/","excerpt":"","text":"","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[]}],"categories":[{"name":"databases","slug":"databases","permalink":"http://example.com/categories/databases/"},{"name":"database project","slug":"database-project","permalink":"http://example.com/categories/database-project/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"},{"name":"database course","slug":"database-course","permalink":"http://example.com/categories/database-course/"}],"tags":[{"name":"TiDB","slug":"TiDB","permalink":"http://example.com/tags/TiDB/"},{"name":"tinykv","slug":"tinykv","permalink":"http://example.com/tags/tinykv/"},{"name":"Raft","slug":"Raft","permalink":"http://example.com/tags/Raft/"},{"name":"cmu 15-445","slug":"cmu-15-445","permalink":"http://example.com/tags/cmu-15-445/"}]}